{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/ERAP_CursoPython/blob/main/Modulo2_Fundamentos_AI/RegresionLogistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ednavivianasegura/ERAP_CursoPython.git"
      ],
      "metadata": {
        "id": "TX3iNtXN6C4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/ERAP_CursoPython/Modulo2_Fundamentos_AI\")"
      ],
      "metadata": {
        "id": "wv9XyelM6Jhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMA8365t4lvU"
      },
      "source": [
        "# Regresión Logística\n",
        "\n",
        "La **regresión logística** es una técnica fundamental tanto en estadística como en machine learning, especialmente útil cuando queremos predecir un resultado binario, es decir, una situación donde solo hay dos posibles salidas: por ejemplo, “tiene una enfermedad” o “no la tiene”, “clic” o “no clic”, “aprobado” o “reprobado”.\n",
        "\n",
        "Este tipo de modelo no solo predice una clase, sino que estima la probabilidad de que ocurra un determinado evento, lo que permite tomar decisiones más informadas. Por eso es ampliamente utilizada en áreas como la medicina, el marketing y las ciencias sociales.\n",
        "\n",
        "## ¿Cómo Funciona la Regresión Logística?\n",
        "\n",
        "En lugar de predecir un valor numérico (como haría una regresión lineal), la regresión logística **estima la probabilidad** de un resultado binario. La clave está en transformar una combinación lineal de las variables de entrada mediante una función especial llamada **sigmoide**, que devuelve valores entre 0 y 1.\n",
        "\n",
        "$$\n",
        "P(Y=1 | X) = \\frac{1}{1 + e^{-Z}}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-miKoq94lvX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generar datos para x\n",
        "x_min, x_max = -10, 10\n",
        "x_values = np.linspace(x_min, x_max, 500)\n",
        "\n",
        "# Calcular la función sigmoidal\n",
        "sigma = 1 / (1 + np.exp(-x_values))\n",
        "\n",
        "# Graficar la función sigmoidal\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_values, sigma, label='Función Sigmoidal', color='blue')\n",
        "plt.xlabel('Valores de x (Característica)')\n",
        "plt.ylabel('Probabilidad de Pertenencia a la Clase Positiva (0-1)')\n",
        "plt.title('Grafica de la Función Sigmoidal en Regresión Logística')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NFnOamG4lvY"
      },
      "source": [
        "  # Cálculo de la Función de Regresión Logística\n",
        "\n",
        "La fórmula general del modelo es:\n",
        "$$\n",
        "P(Y=1 | X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n)}}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $ P(Y=1 | X) $: Es la probabilidad de que la variable dependiente $ Y $ sea igual a 1 (evento de interés) dado un conjunto de variables independientes $ X $.\n",
        "\n",
        "- $Z = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n$ son los parámetros del modelo que deben ajustarse a los datos.\n",
        "\n",
        "- $ X_i $: son las variables de entrada (edad, hábitos, niveles de glucosa, etc).\n",
        "\n",
        "## Pasos para Calcular la Función de Regresión Logística\n",
        "\n",
        "### Paso 1: Recolección de Datos\n",
        "\n",
        "El punto de partida es contar con datos donde conozcamos el resultado (por ejemplo, si una persona tiene una enfermedad o no) y algunas características que puedan estar relacionadas con ese resultado (edad, peso, antecedentes familiares, etc.).\n",
        "\n",
        "### Paso 2: Definir la Función Lineal\n",
        "\n",
        "Se construye una combinación lineal de las variables independientes:\n",
        "\n",
        "$$\n",
        "Z = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n\n",
        "$$\n",
        "\n",
        "### Paso 3: Aplicar la Función Sigmoide\n",
        "\n",
        "La función sigmoide convierte el valor de $ Z $ en una probabilidad:\n",
        "\n",
        "$$\n",
        "P(Y=1 | X) = \\frac{1}{1 + e^{-Z}} = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n)}}\n",
        "$$\n",
        "Esto garantiza que el resultado siempre esté entre 0 y 1.\n",
        "\n",
        "### Paso 4: Interpretar los Coeficientes\n",
        "\n",
        "Cada $ \\beta_i $ indica cómo cambia la probabilidad con respecto a $ X_i $. El valor $ e^{\\beta_i} $ representa el efecto multiplicativo en las *odds* (chances).\n",
        "\n",
        "### Paso 5: Ajuste del Modelo\n",
        "\n",
        "Se ajustan los coeficientes usando máxima verosimilitud.\n",
        "\n",
        "\n",
        "### Paso 6: Evaluación del Modelo\n",
        "\n",
        "Se miden métricas como precisión, sensibilidad, F1-score y curva ROC.\n",
        "\n",
        "## Proceso\n",
        "\n",
        "1. **Recolección de Datos**: Obtención de un conjunto de datos donde se conoce el resultado (variable dependiente) y las características (variables independientes).\n",
        "2. **Entrenamiento del Modelo**: Ajustar los coeficientes del modelo usando métodos como la máxima verosimilitud.\n",
        "3. **Predicción**: Usar el modelo entrenado para predecir la probabilidad de que ocurran ciertos eventos en nuevos datos.\n",
        "4. **Evaluación**: Medir el rendimiento del modelo mediante métricas como la curva ROC, la precisión y el F1-score.\n",
        "\n",
        "# Aplicaciones en Investigación Clínica y Salud\n",
        "\n",
        "- **Predicción de enfermedades**: Estimar riesgo de diabetes, hipertensión, etc.\n",
        "- **Evaluación de tratamientos**: Analizar la eficacia de intervenciones médicas.\n",
        "- **Factores de riesgo**: Identificar variables asociadas a condiciones clínicas.\n",
        "- **Resultados quirúrgicos**: Predecir complicaciones postoperatorias.\n",
        "- **Salud pública**: Estudiar la distribución de enfermedades en poblaciones.\n",
        "- **Resultados clínicos**: Estimar riesgo de hospitalización o mortalidad.\n",
        "- **Salud mental**: Analizar variables asociadas a depresión, ansiedad, etc.\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "La regresión logística es una herramienta clave para modelar situaciones donde el resultado es binario. Permite comprender mejor los datos, estimar probabilidades y apoyar la toma de decisiones en contextos reales, especialmente en áreas como la salud, donde su impacto puede ser directo y significativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpdAN7Nf0jv1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Cargar la base de datos\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'\n",
        "columns = ['Embarazos', 'Glucosa', 'Presion', 'Piel', 'Insulina', 'IMC', 'Pedigri', 'Edad', 'Resultado']\n",
        "data = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Configurar el estilo de Seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Crear un pairplot y guardarlo en una variable\n",
        "pairplot = sns.pairplot(data, hue='Resultado')\n",
        "\n",
        "# Establecer el título al inicio del gráfico\n",
        "pairplot.fig.suptitle('Pairplot del Conjunto de Datos de Diabetes Pima Indian', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whJZUA1-3yWH"
      },
      "source": [
        "## Preparación para lanzar el modelo\n",
        "### Se crea los datos de entreno y validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUjIAy33340v"
      },
      "outputs": [],
      "source": [
        "# Separar las variables independientes y dependientes\n",
        "X = data.drop('Resultado', axis=1)\n",
        "y = data['Resultado']\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y ajustar el modelo de regresión logística\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Mostrar los coeficientes\n",
        "coefficients = pd.DataFrame(model.coef_, columns=X.columns)\n",
        "coefficients['intercept'] = model.intercept_\n",
        "coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbOLdYDH6RzL"
      },
      "source": [
        "# Explicación de los Resultados de la Regresión Logística\n",
        "\n",
        "Los resultados de la función sigmoide en el contexto de nuestro modelo de regresión logística se presentan a continuación. Cada coeficiente representa la influencia de las variables independientes sobre la log-odds de tener diabetes.\n",
        "\n",
        "### Coeficientes del Modelo\n",
        "\n",
        "| Variable                           | Coeficiente   |\n",
        "|-----------------------------------|---------------|\n",
        "| **Pregnancies**                   | 0.064372      |\n",
        "| **Glucose**                       | 0.034094      |\n",
        "| **BloodPressure**                 | -0.013879     |\n",
        "| **SkinThickness**                 | 0.003291      |\n",
        "| **Insulin**                       | -0.001803     |\n",
        "| **BMI**                           | 0.102608      |\n",
        "| **DiabetesPedigreeFunction**     | 0.626886      |\n",
        "| **Age**                           | 0.037097      |\n",
        "| **Intercept**                     | -9.006833     |\n",
        "\n",
        "### Función Sigmoide con Coeficientes\n",
        "\n",
        "La función sigmoide utilizada en la regresión logística se define como:\n",
        "\n",
        "$$\n",
        "P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_n X_n)}}\n",
        "$$\n",
        "\n",
        "Para nuestro modelo, la función sigmoide se puede expresar con los coeficientes de la siguiente manera:\n",
        "\n",
        "$$\n",
        "P(Y=1|X) = \\frac{1}{1 + e^{-(-9.006833 + 0.064372 \\cdot X_1 + 0.034094 \\cdot X_2 - 0.013879 \\cdot X_3 + 0.003291 \\cdot X_4 - 0.001803 \\cdot X_5 + 0.102608 \\cdot X_6 + 0.626886 \\cdot X_7 + 0.037097 \\cdot X_8)}}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- \\( X_1 \\) representa el número de **Embarazos**.\n",
        "- \\( X_2 \\) representa el nivel de **Glucosa**.\n",
        "- \\( X_3 \\) representa la **Presion en sagre**.\n",
        "- \\( X_4 \\) representa el **Grosor de la piel**.\n",
        "- \\( X_5 \\) representa el nivel de **Insulina**.\n",
        "- \\( X_6 \\) representa el **IMC**.\n",
        "- \\( X_7 \\) representa la **Pedigri**.\n",
        "- \\( X_8 \\) representa la **Edad**.\n",
        "\n",
        "### Interpretación de los Coeficientes\n",
        "### Interpretación de los Coeficientes\n",
        "\n",
        "1. **Embarazos (0.064372)**:\n",
        "   - Un aumento de una unidad en el número de embarazos se asocia con un incremento del 6.44% en la log-odds de desarrollar diabetes, manteniendo las otras variables constantes.\n",
        "\n",
        "2. **Glucosa (0.034094)**:\n",
        "   - Un aumento de una unidad en el nivel de glucosa se asocia con un incremento del 3.41% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "3. **Presion en sagre (-0.013879)**:\n",
        "   - Un aumento de una unidad en la presión arterial se asocia con una disminución del 1.39% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "4. **Grosor de la piel (0.003291)**:\n",
        "   - Un aumento de una unidad en el grosor de la piel se asocia con un ligero incremento del 0.33% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "5. **Insulina (-0.001803)**:\n",
        "   - Un aumento de una unidad en el nivel de insulina se asocia con una disminución del 0.18% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "6. **IMC (0.102608)**:\n",
        "   - Un aumento de una unidad en el índice de masa corporal se asocia con un aumento significativo del 10.26% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "7. **Pedigri (0.626886)**:\n",
        "   - Un aumento en la función de pedigree de diabetes se asocia con un incremento notable del 62.69% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "8. **Edad (0.037097)**:\n",
        "   - Un aumento de un año en la edad se asocia con un incremento del 3.71% en la log-odds de desarrollar diabetes.\n",
        "\n",
        "9. **Intercepto (-9.006833)**:\n",
        "   - El intercepto representa la log-odds de que una persona tenga diabetes cuando todas las variables independientes son cero. Un valor tan negativo indica que la probabilidad de tener diabetes es muy baja cuando no se consideran las variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJTwReSPhqrV"
      },
      "outputs": [],
      "source": [
        "# 2. Seleccionar características y objetivo (usamos solo 'Glucose')\n",
        "X = X[['Glucosa']]\n",
        "y = y\n",
        "\n",
        "# 3. Dividir en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Entrenar el modelo de regresión logística (sin regularización)\n",
        "model = LogisticRegression( solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Obtener coeficientes del modelo\n",
        "b0 = model.intercept_[0]\n",
        "b1 = model.coef_[0][0]\n",
        "\n",
        "# 6. Generar valores para la curva sigmoide\n",
        "x_values = np.linspace(X['Glucosa'].min(), X['Glucosa'].max(), 300)\n",
        "y_sigmoid = 1 / (1 + np.exp(-(b0 + b1 * x_values)))\n",
        "\n",
        "# 7. Calcular punto de corte (donde y=0.5)\n",
        "x_corte = -b0 / b1\n",
        "\n",
        "# 8. Predecir en el conjunto de test\n",
        "y_pred = model.predict(X_test)\n",
        "colores = ['green' if pred == real else 'red' for pred, real in zip(y_pred, y_test)]\n",
        "\n",
        "# 9. Configurar la gráfica\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Curva sigmoide\n",
        "plt.plot(x_values, y_sigmoid, label='Función Sigmoide', color='blue')\n",
        "\n",
        "# Líneas horizontales y verticales\n",
        "plt.axhline(0.5, color='black', linestyle='--', label='Umbral 0.5')\n",
        "plt.axvline(x_corte, color='orange', linestyle='--', label=f'Corte en x={x_corte:.2f}')\n",
        "\n",
        "# Puntos de test con jitter para visualización\n",
        "np.random.seed(42)\n",
        "espaciado = np.random.normal(0, 0.008, size=len(y_test))  # Pequeño espaciado en el eje Y\n",
        "plt.scatter(X_test['Glucosa'], y_test + espaciado, c=colores, alpha=0.6,\n",
        "            edgecolor='k', label='Datos de test (0: No diabetes, 1: Diabetes)')\n",
        "\n",
        "# Configuración estética\n",
        "plt.xlabel('Nivel de Glucosa', fontsize=12)\n",
        "plt.ylabel('Probabilidad / Clase Real', fontsize=12)\n",
        "plt.title('Clasificación de Diabetes con Regresión Logística', fontsize=14)\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsmF0IQeEYc0"
      },
      "source": [
        "## Matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho0yrkgK9uHX"
      },
      "outputs": [],
      "source": [
        "# Separar las variables independientes y dependientes\n",
        "X = data.drop('Resultado', axis=1)\n",
        "y = data['Resultado']\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y ajustar el modelo de regresión logística\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Crear una visualización de la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['No Diabetes', 'Diabetes'],\n",
        "            yticklabels=['No Diabetes', 'Diabetes'])\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Realidad')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7KPhduR4lvb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "plt.figure(figsize=(10, 6))\n",
        "img = mpimg.imread('Imagenes/Errores.jpg')\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqk9FjS04lvb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 9))\n",
        "img = mpimg.imread(\"Imagenes/Exactitud.jpg\")\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ENRbpkD4lvb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 9))\n",
        "img = mpimg.imread(\"Imagenes/Precision.jpg\")\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArzHSE1U4lvb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 9))\n",
        "img = mpimg.imread(\"Imagenes/Sensibilidad.jpg\")\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHssPU2i4lvb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 9))\n",
        "img = mpimg.imread(\"Imagenes/Especificidad.jpg\")\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiYFVfK94lvb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 9))\n",
        "img = mpimg.imread(\"Imagenes/F1.jpg\")\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: oculta los ejes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWz-9cngEi7x"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred, target_names=['No Diabetes', 'Diabetes'])\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuCTO1GU4lvc"
      },
      "source": [
        "## Mejorando la precisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WoxkaIbNDXd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar el dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columnas = ['Embarazos', 'Glucosa', 'Presion', 'Piel', 'Insulina', 'IMC', 'Pedigri', 'Edad', 'Resultado']\n",
        "datos = pd.read_csv(url, names=columnas)\n",
        "\n",
        "# Separar características y objetivo\n",
        "X = datos.drop('Resultado', axis=1)\n",
        "y = datos['Resultado']\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Entrenar modelo de regresión logística\n",
        "modelo = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Obtener probabilidades predichas\n",
        "probabilidades = modelo.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Generar rangos de umbrales\n",
        "umbrales = np.arange(0.0, 1.01, 0.01)\n",
        "precisiones = []\n",
        "\n",
        "# Calcular precisión para cada umbral\n",
        "for umbral in umbrales:\n",
        "    predicciones = (probabilidades >= umbral).astype(int)\n",
        "    precision = accuracy_score(y_test, predicciones)\n",
        "    precisiones.append(precision)\n",
        "\n",
        "# Encontrar mejor umbral\n",
        "mejor_precision = max(precisiones)\n",
        "mejor_umbral = umbrales[np.argmax(precisiones)]\n",
        "\n",
        "# Graficar resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(umbrales, precisiones, label='Precisión')\n",
        "plt.scatter(mejor_umbral, mejor_precision, color='red',\n",
        "            label=f'Máxima precisión: {mejor_precision:.3f} en umbral {mejor_umbral:.2f}')\n",
        "plt.xlabel('Umbral de Clasificación')\n",
        "plt.ylabel('Precisión')\n",
        "plt.title('Precisión vs Umbral de Clasificación')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mejor umbral: {mejor_umbral:.2f} con precisión: {mejor_precision:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BeH2Kh0Z-H_",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def matriz_confusion_umbral(y_true, y_probs, umbral=0.5):\n",
        "    \"\"\"\n",
        "    Genera matriz de confusión para un modelo de clasificación binaria\n",
        "    con posibilidad de ajustar el umbral de decisión.\n",
        "\n",
        "    Parámetros:\n",
        "    y_true (array): Valores verdaderos\n",
        "    y_probs (array): Probabilidades predichas para la clase positiva\n",
        "    umbral (float): Umbral para clasificación (default 0.5)\n",
        "\n",
        "    Retorna:\n",
        "    DataFrame: Matriz de confusión con etiquetas\n",
        "    \"\"\"\n",
        "    # Aplicar umbral para convertir probabilidades a clases predichas\n",
        "    y_pred = (y_probs >= umbral).astype(int)\n",
        "\n",
        "    # Generar matriz de confusión\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Convertir a DataFrame con etiquetas\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=['Actual Negativo', 'Actual Positivo'],\n",
        "                         columns=['Predicho Negativo', 'Predicho Positivo'])\n",
        "    return cm_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnTgQpXIZ_gB",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "matriz_confusion_umbral(y_test,probabilidades, umbral=0.65 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbOnrE13rJPg",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "matriz_confusion_umbral(y_test,probabilidades, umbral=0.5 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf5Db_sq0-NP"
      },
      "source": [
        "## Mejorando el F1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVEHyqZw04Dr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar el dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columnas = ['Embarazos', 'Glucosa', 'Presion', 'Piel', 'Insulina', 'IMC', 'Pedigri', 'Edad', 'Resultado']\n",
        "datos = pd.read_csv(url, names=columnas)\n",
        "\n",
        "# Separar características y objetivo\n",
        "X = datos.drop('Resultado', axis=1)\n",
        "y = datos['Resultado']\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Entrenar modelo de regresión logística\n",
        "# Probar diferentes solvers y parámetros de regularización\n",
        "modelo = LogisticRegression(solver='liblinear', penalty='l1', C=0.1, random_state=42, max_iter=1000)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Obtener probabilidades predichas\n",
        "probabilidades = modelo.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Generar rangos de umbrales\n",
        "umbrales = np.arange(0.0, 1.01, 0.01)\n",
        "f1_scores = []\n",
        "\n",
        "# Calcular F1-score para cada umbral\n",
        "for umbral in umbrales:\n",
        "    predicciones = (probabilidades >= umbral).astype(int)\n",
        "    f1 = f1_score(y_test, predicciones)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Encontrar mejor umbral\n",
        "mejor_f1 = max(f1_scores)\n",
        "mejor_umbral = umbrales[np.argmax(f1_scores)]\n",
        "\n",
        "# Graficar resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(umbrales, f1_scores, label='F1-score')\n",
        "plt.scatter(mejor_umbral, mejor_f1, color='red',\n",
        "            label=f'Máximo F1-score: {mejor_f1:.3f} en umbral {mejor_umbral:.2f}')\n",
        "plt.xlabel('Umbral de Clasificación')\n",
        "plt.ylabel('F1-score')\n",
        "plt.title('F1-score vs Umbral de Clasificación')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Mejor umbral: {mejor_umbral:.2f} con F1-score: {mejor_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3WSHwjM1QEJ",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "matriz_confusion_umbral(y_test,probabilidades, umbral=0.25 )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}