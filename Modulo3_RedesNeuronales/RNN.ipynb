{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGQ0R4CI62nEs4hw2/q+qU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ednavivianasegura/ERAP_CursoPython/blob/main/Modulo3_RedesNeuronales/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autores:** Edna Viviana Segura Alvarado - Hans Mauricio Carrillo Hernández\n",
        "\n",
        "**Institución:** Universidad de la Rioja\n",
        "\n",
        "**Fecha:** Junio/2025\n",
        "\n",
        "**Redes neuronales recurrentes (RNN)**\n",
        "\n",
        "\n",
        "Nota: basado en [RNN_C](https://www.datacamp.com/es/tutorial/tutorial-for-recurrent-neural-networks)\n"
      ],
      "metadata": {
        "id": "df4SwpVU5rnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Redes Neuronales Recurrentes (RNN)  \n",
        "\n",
        "Las **Redes Neuronales Recurrentes (RNN)** son un tipo de red neuronal artificial diseñada para trabajar con datos secuenciales (como texto, series temporales o audio). A diferencia de las redes neuronales tradicionales, las RNN mantienen una **memoria interna** que les permite recordar información de pasos anteriores, lo que las hace ideales para:  \n",
        "\n",
        "- Predicción de valores financieros.  \n",
        "- Generación de texto (traducción, resúmenes).  \n",
        "- Procesamiento de voz (ej.: Siri, Google Voice Search).  \n",
        "\n",
        "#### Características clave:  \n",
        "1. **Dependencia secuencial**: la salida en el paso `t` depende de las entradas anteriores (`t-1`, `t-2`, ...).  \n",
        "2. **Compartición de parámetros**: usan los mismos pesos en todas las capas (eficiencia computacional).  \n",
        "3. **Ajuste durante el entrenamiento**: los pesos y sesgos se optimizan mediante backpropagation a través del tiempo (BPTT).  \n",
        "\n",
        "#### vs. Redes Feed-Forward:  \n",
        "| **RNN** | **Feed-Forward** |  \n",
        "|---------|------------------|  \n",
        "| Memoria interna (estado oculto) | Sin memoria |  \n",
        "| Salidas dependientes | Salidas independientes |  \n",
        "| Ideal para secuencias | Ideal para datos estáticos |  \n"
      ],
      "metadata": {
        "id": "VqzEQFURg1Rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/1.png?raw=true\" alt=\"1\" width=\"50%\" height=\"50%\">  \n",
        "</center>"
      ],
      "metadata": {
        "id": "pjwAVH53hgp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funcionamiento de las Redes Neuronales Recurrentes (RNN)\n",
        "\n",
        "\n",
        "Las RNN procesan información secuencial mediante bucles recurrentes, donde cada salida depende tanto de la entrada actual como de las anteriores. Este mecanismo les permite \"recordar\" patrones temporales, algo imposible en redes neuronales tradicionales.\n",
        "\n",
        "**Arquitectura clave:**\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/2.png?raw=true\" alt=\"2\" width=\"20%\" height=\"5%\">  \n",
        "</center>\n",
        "\n",
        "* Capa de entrada (X): recibe los datos (ej.: palabras, valores temporales).\n",
        "\n",
        "* Capa oculta (A):\n",
        "\n",
        "comparte los mismos parámetros (pesos y sesgos) en todos los pasos de tiempo.\n",
        "\n",
        "Usa funciones de activación (como tanh o ReLU) para transformar los datos.\n",
        "\n",
        "* Bucle recurrente: el estado oculto se retroalimenta, combinando información nueva con la pasada.\n",
        "\n",
        "### Entrenamiento: Backpropagation Through Time (BPTT)\n",
        "\n",
        "Diferencias con backpropagation tradicional:\n",
        "\n",
        "* BPTT calcula gradientes a lo largo de la secuencia temporal, sumando errores en cada paso.\n",
        "\n",
        "* Optimiza parámetros compartidos, lo que reduce la complejidad computacional."
      ],
      "metadata": {
        "id": "Z3DXa4-GmmJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tipos de RNN y sus aplicaciones\n",
        "\n",
        "Gracias a su flexibilidad en longitudes de entrada/salida, las RNN destacan en tareas secuenciales:\n",
        "\n",
        "## Tabla Comparativa: Tipos de RNN y sus Aplicaciones\n",
        "\n",
        "| Tipo de RNN        | Estructura          | Ejemplo de Aplicación      | Caso de Uso Concreto               | Framework Implementación |\n",
        "|--------------------|---------------------|---------------------------|------------------------------------|--------------------------|\n",
        "| **Uno-a-Uno**      | `x → h → y`         | Clasificación de imágenes | MNIST/CIFAR-10                     | `torch.nn.RNN`           |\n",
        "| **Uno-a-Muchos**   | `x → h → [y₁...yₙ]` | Generación de música      | Composición de melodías MIDI       | `tf.keras.SimpleRNN`     |\n",
        "| **Muchos-a-Uno**   | `[x₁...xₙ] → h → y` | Análisis de sentimiento   | Clasificación de reseñas en Amazon | `nn.RNN` (PyTorch)       |\n",
        "| **Muchos-a-Muchos**| `[x₁...xₙ] → h → [y₁...yₙ]` | Traducción automática | Seq2Seq (Inglés-Español)          | `tf.keras.LSTM`          |"
      ],
      "metadata": {
        "id": "_Bf-GNifoN0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/3.png?raw=true\" alt=\"3\" width=\"50%\" height=\"50%\">  \n",
        "</center>"
      ],
      "metadata": {
        "id": "dXw60Jqpog-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparativa: Redes Neuronales Convolucionales (CNN) vs. Recurrentes (RNN)\n",
        "\n",
        "**Redes Neuronales Convolucionales (CNN)**\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/4.png?raw=true\" alt=\"4\" width=\"50%\" height=\"50%\">  \n",
        "</center>\n",
        "\n",
        "**Arquitectura típica:**\n",
        "\n",
        "\n",
        "```\n",
        "Conv2D → ReLU → MaxPooling → Flatten → Dense\n",
        "```\n",
        "\n",
        "**Aplicaciones principales:**\n",
        "\n",
        "\n",
        "* Clasificación de imágenes (ej: MNIST, ImageNet)\n",
        "\n",
        "* Procesamiento de video\n",
        "\n",
        "* Detección de objetos\n",
        "\n",
        "**Ventajas clave:**\n",
        "\n",
        "* Captura patrones espaciales mediante filtros convolucionales\n",
        "\n",
        "* Invariante a traslaciones en imágenes\n",
        "\n",
        "* Eficiente para datos grid-like (píxeles)\n",
        "\n",
        "**Redes Neuronales Recurrentes (RNN)**\n",
        "\n",
        "**Arquitectura típica:**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "RNNCell → Tanh → Dense\n",
        "```\n",
        "\n",
        "**Aplicaciones principales:**\n",
        "\n",
        "* Procesamiento de lenguaje natural\n",
        "\n",
        "* Análisis de series temporales\n",
        "\n",
        "* Traducción automática\n",
        "\n",
        "\n",
        "### Comparativa CNN vs RNN (Formato Notebook)\n",
        "\n",
        "\n",
        "\n",
        "| Característica          | CNN                          | RNN                          |\n",
        "|-------------------------|------------------------------|------------------------------|\n",
        "| **Tipo de datos**       | Datos espaciales (imágenes)  | Datos secuenciales (texto/series) |\n",
        "| **Arquitectura**        | Capas convolucionales        | Bucles recurrentes           |\n",
        "| **Mecanismo**          | Filtros para patrones locales| Memoria de estados anteriores|\n",
        "| **Backpropagation**    | Backprop estándar            | BPTT (Through Time)          |\n",
        "| **Longitud E/S**       | Tamaño fijo                  | Longitud variable            |\n",
        "| **Ejemplo típico**     | ResNet (clasificación)       | LSTM (traducción)            |\n",
        "| **Ventaja clave**      | Invariante a traslaciones    | Modela dependencias temporales|\n",
        "| **Limitación**         | Requiere mucho dato          | Problemas de gradiente       |\n",
        "\n",
        "\n",
        "### Arquitecturas RNN Avanzadas\n",
        "LSTM (Long Short-Term Memory)\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/5.png?raw=true\" alt=\"5\" width=\"50%\" height=\"50%\">  \n",
        "</center>\n",
        "\n",
        "**Ventajas:**\n",
        "\n",
        "* Memoria a largo plazo\n",
        "\n",
        "* Evita problemas de gradiente\n",
        "\n",
        "* GRU (Gated Recurrent Unit)\n",
        "\n",
        "**Diferencias clave vs LSTM:**\n",
        "\n",
        "* Menos parámetros\n",
        "\n",
        "* Combina forget/input gates\n",
        "\n",
        "* Similar rendimiento en muchos casos\n",
        "\n"
      ],
      "metadata": {
        "id": "cvio26HOqTm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquitecturas Avanzadas para Modelado Secuencial\n",
        "\n",
        "## Long Short-Term Memory (LSTM)\n",
        "\n",
        "### Innovación clave:\n",
        "Las LSTMs superan las limitaciones de las RNN tradicionales mediante un **mecanismo de puertas** que regula el flujo de información, resolviendo los problemas de:\n",
        "- Desvanecimiento de gradientes\n",
        "- Explosión de gradientes\n",
        "\n",
        "**Componentes críticos:**\n",
        "\n",
        "* Puerta Forget: decide qué información descartar\n",
        "\n",
        "* Puerta Input: actualiza la memoria con datos relevantes\n",
        "\n",
        "* Puerta Output: controla qué información pasa al siguiente paso\n",
        "\n",
        "**Aplicaciones destacadas:**\n",
        "\n",
        "* Traducción automática (ej: Google Translate)\n",
        "\n",
        "* Generación de subtítulos automáticos\n",
        "\n",
        "* Predicción de series temporales financieras\n",
        "\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/6.png?raw=true\" alt=\"6\" width=\"50%\" height=\"50%\">  \n",
        "</center>"
      ],
      "metadata": {
        "id": "XqC1n1dfsu02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gated Recurrent Unit (GRU)\n",
        "\n",
        "\n",
        "<center>\n",
        " <img src=\"https://github.com/ednavivianasegura/AccesoImages/blob/main/RNN/7.png?raw=true\" alt=\"7\" width=\"50%\" height=\"50%\">  \n",
        "</center>\n",
        "\n",
        "### Evolución de las LSTM:\n",
        "\n",
        "Las GRUs simplifican la arquitectura manteniendo la eficacia, mediante:\n",
        "\n",
        "* 2 puertas fundamentales (vs 3 en LSTM)\n",
        "\n",
        "* Menor costo computacional\n",
        "\n",
        "\n",
        "| Característica       | LSTM                          | GRU                          |\n",
        "|----------------------|-------------------------------|-------------------------------|\n",
        "| **Puertas**          | 3 (Forget/Input/Output)       | 2 (Update/Reset)              |\n",
        "| **Estado**           | Celda (Cₜ) + Oculto (hₜ)      | Solo estado oculto (hₜ)       |\n",
        "| **Parámetros**       | ~30% más                       | Más eficiente                 |\n",
        "| **Velocidad**        | Más lento                     | 20-30% más rápido             |\n",
        "| **Precisión**        | Ideal para secuencias largas   | Comparable en secuencias medias |\n",
        "| **Implementación**   | `keras.layers.LSTM()`          | `keras.layers.GRU()`           |\n"
      ],
      "metadata": {
        "id": "eW3sj-TCttHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción de Precios de MasterCard usando Redes Neuronales Recurrentes\n",
        "\n",
        "## Objetivo:\n",
        "\n",
        "Desarrollar modelos predictivos para series temporales financieras utilizando arquitecturas LSTM y GRU, aplicadas al histórico de acciones de MasterCard (2006-2021).\n",
        "\n",
        "### Dataset y Metodología\n",
        "\n",
        "**Fuente de datos:**  \n",
        "[Dataset de Kaggle](https://www.kaggle.com/datasets/kalilurrahman/mastercard-stock-data-latest-and-updated) con registros diarios desde 25/05/2006 hasta 11/10/2021\n",
        "\n"
      ],
      "metadata": {
        "id": "u5jpMvpuuomj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Librerías\n",
        "\n",
        "\n",
        "# ======================\n",
        "# IMPORTACIÓN DE LIBRERÍAS\n",
        "# ======================\n",
        "# Procesamiento numérico y estructuras de datos\n",
        "import numpy as np  # Operaciones matriciales y numéricas eficientes\n",
        "import pandas as pd  # Manipulación de DataFrames y series temporales\n",
        "\n",
        "# Visualización\n",
        "import matplotlib.pyplot as plt  # Gráficos 2D y visualización de datos\n",
        "\n",
        "# Preprocesamiento y evaluación\n",
        "from sklearn.preprocessing import MinMaxScaler  # Normalización de datos [0,1]\n",
        "from sklearn.metrics import mean_squared_error  # Métrica de error cuadrático medio\n",
        "\n",
        "# Modelado con Keras\n",
        "from tensorflow.keras.models import Sequential  # Modelo secuencial API\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,        # Capas totalmente conectadas\n",
        "    LSTM,         # Long Short-Term Memory (para secuencias)\n",
        "    Dropout,      # Regularización por desactivación aleatoria\n",
        "    GRU,          # Gated Recurrent Unit (alternativa a LSTM)\n",
        "    Bidirectional # LSTM bidireccional (contexto futuro+pasado)\n",
        ")\n",
        "from tensorflow.keras.optimizers import SGD  # Optimizador Descenso Gradiente Estocástico\n",
        "from tensorflow.random import set_seed  # Control de aleatoriedad en TF\n",
        "\n",
        "# Para acceder a los datos\n",
        "import kagglehub\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "\n",
        "# ======================\n",
        "# CONFIGURACIÓN INICIAL\n",
        "# ======================\n",
        "\"\"\"\n",
        "Establecimiento de semillas para reproducibilidad:\n",
        "- TensorFlow/Keras (set_seed)\n",
        "- NumPy (np.random.seed)\n",
        "Valor 455 seleccionado arbitrariamente para consistencia\n",
        "\"\"\"\n",
        "set_seed(455)  # Semilla para generadores aleatorios de TensorFlow\n",
        "np.random.seed(455)  # Semilla para NumPy y otras librerías basadas en él\n",
        "\n"
      ],
      "metadata": {
        "id": "f3JYtwHiu_EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código importa las bibliotecas necesarias para el análisis de datos y las tareas de manipulación. - numpy y pandas se utilizan para la manipulación y el análisis de datos. - matplotlib se utiliza para la visualización de datos. - MinMaxScaler y mean_squared_error se utilizan para el preprocesamiento y la evaluación de datos, respectivamente. - Las clases Sequential, Dense, LSTM, Dropout, GRU, Bidirectional y SGD pertenecen al módulo tensorflow.keras, que se utiliza para construir y entrenar modelos de aprendizaje profundo. - set_seed y np.random.seed se utilizan para establecer la semilla aleatoria con fines de reproducibilidad. En general, este código configura el entorno necesario para construir y entrenar modelos de aprendizaje profundo para el análisis de series temporales."
      ],
      "metadata": {
        "id": "XN5CBeeiv0IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis inicial de datos\n",
        "\n",
        "Imoportamos los datos, añadimos la columna Date como índice y en formato DataTime. Eliminamos dos variables que son irrelevantes en nuestro análisis."
      ],
      "metadata": {
        "id": "7QyM3tV_v4ga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvevlZR6fqos"
      },
      "outputs": [],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kalilurrahman/mastercard-stock-data-latest-and-updated\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "print(os.listdir(path))\n",
        "\n",
        "# Construir la ruta completa al archivo deseado\n",
        "history_path = os.path.join(path, 'Mastercard_stock_history.csv')\n",
        "\n",
        "dataset = pd.read_csv(\n",
        "    history_path, index_col=\"Date\", parse_dates=[\"Date\"]\n",
        ").drop([\"Dividends\", \"Stock Splits\"], axis=1)\n",
        "print(dataset.head())\n",
        "\n",
        "display(dataset)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código lee un archivo CSV llamado \"Mastercard_stock_history.csv\" directamente desde kagglehub.\n",
        "El resultado muestra los valores de Open, High, Low, Close y Volume de cada día del conjunto de datos, con la columna Date como índice."
      ],
      "metadata": {
        "id": "uXF7Rd7uzLDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función .describe() sirve para analizar los datos iniciales.\n",
        "\n",
        "Nos centraremos en la columna High, ya que vamos a utilizarla para entrenar el modelo.\n",
        "También se pueden elegir las columnas Close u Open para una característica del modelo, pero High tiene más sentido, ya que  proporciona información de lo alto que subieron los valores de la acción en un día determinado.\n",
        "\n"
      ],
      "metadata": {
        "id": "KZgYA3y3zaxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.describe())\n",
        "print(dataset.isna().sum())"
      ],
      "metadata": {
        "id": "SOzUxy4jz3Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Función de limpieza específica para tu formato\n",
        "def clean_date_index(df):\n",
        "    \"\"\"\n",
        "    Limpia fechas en formato '2006-05-25 00:00:00-04:00'\n",
        "    convirtiéndolas a datetime sin timezone\n",
        "    \"\"\"\n",
        "    # Extraer solo la parte de la fecha (antes del primer espacio)\n",
        "    clean_dates = [str(date).split()[0] for date in df.index]\n",
        "\n",
        "    # Convertir a datetime\n",
        "    df.index = pd.to_datetime(clean_dates)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 3. Aplicar la limpieza\n",
        "dataset = clean_date_index(dataset)\n",
        "\n",
        "# 4. Verificar el resultado\n",
        "print(\"Formato del índice después de limpieza:\")\n",
        "print(type(dataset.index))\n",
        "print(dataset.index[:5])  # Mostrar las primeras 5 fechas\n",
        "print(\"\\nDatos limpios:\")\n",
        "print(dataset.head())"
      ],
      "metadata": {
        "id": "zChKCZWWf5sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creamos los conjuntos de entrenamiento y prueba"
      ],
      "metadata": {
        "id": "8tDKV72t0Pt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tstart = 2016\n",
        "tend = 2022\n",
        "\n",
        "def train_test_plot(dataset, tstart, tend):\n",
        "    dataset.loc[f\"{tstart}\":f\"{tend}\", \"High\"].plot(figsize=(16, 4), legend=True)\n",
        "    dataset.loc[f\"{tend+1}\":, \"High\"].plot(figsize=(16, 4), legend=True)\n",
        "    plt.legend([f\"Train (Before {tend+1})\", f\"Test ({tend+1} and beyond)\"])\n",
        "    plt.title(\"MasterCard stock price\")\n",
        "    plt.show()\n",
        "\n",
        "train_test_plot(dataset,tstart,tend)\n"
      ],
      "metadata": {
        "id": "zGKdKMbl3Eia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define una función llamada train_test_plot que recibe tres argumentos: dataset, tstart y tend. El argumento dataset es un DataFrame de pandas que contiene datos sobre el precio de las acciones de MasterCard. Los argumentos tstart y tend son números enteros que representan los años inicial y final de los datos que se van a representar. Dentro de la función, el método loc se utiliza para seleccionar un subconjunto del DataFrame dataset en función de los argumentos tstart y tend. En concreto, se selecciona la columna High del DataFrame para los años comprendidos entre tstart y tend y, a continuación, para los años posteriores a tend+1. Los subconjuntos resultantes se representan con el método plot, con figsize de (16, 4) y legend True. Por último, el módulo plt se utiliza para añadir una leyenda al gráfico, con etiquetas para los datos de entrenamiento y de prueba, así como un título para el gráfico. El gráfico resultante se muestra con el método show. A continuación, se llama a la función train_test_plot con los argumentos dataset, tstart y tend para generar el gráfico.\n",
        "\n",
        "**Preprocesamiento de datos**\n",
        "\n",
        "La función train_test_split divide el conjunto de datos en dos subconjuntos: training_set y test_set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Kw_2LSmpoQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(dataset, tstart, tend):\n",
        "    \"\"\"\n",
        "    Divide el dataset en conjuntos de entrenamiento y prueba basados en años.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    dataset : pd.DataFrame\n",
        "        DataFrame con precios de acciones donde el índice es DateTimeIndex\n",
        "    tstart : int\n",
        "        Año inicial para el conjunto de entrenamiento (inclusive)\n",
        "    tend : int\n",
        "        Año final para el conjunto de entrenamiento (inclusive)\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    tuple: (training_set, test_set)\n",
        "        - training_set: numpy.ndarray con valores 'High' de años de entrenamiento\n",
        "        - test_set: numpy.ndarray con valores 'High' de años de prueba\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Selección del periodo de entrenamiento (inclusive)\n",
        "    # Usa loc con strings que representan rangos temporales\n",
        "    # f\"{tstart}\":f\"{tend}\" selecciona desde enero de tstart hasta diciembre de tend\n",
        "    train = dataset.loc[f\"{tstart}\":f\"{tend}\", \"High\"].values  # Extrae valores como numpy array\n",
        "\n",
        "    # Selección del periodo de prueba (después de tend hasta el final)\n",
        "    # f\"{tend+1}\": selecciona desde enero de tend+1 en adelante\n",
        "    test = dataset.loc[f\"{tend+1}\":, \"High\"].values  # Extrae valores como numpy array\n",
        "\n",
        "    return train, test\n",
        "\n",
        "# Uso de la función:\n",
        "# Asume que dataset tiene un DateTimeIndex y columna 'High'\n",
        "training_set, test_set = train_test_split(dataset, tstart, tend)"
      ],
      "metadata": {
        "id": "FghscDaIpbzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define una función llamada train_test_split que recibe tres argumentos: dataset, tstart y tend. Dentro de la función, crea dos variables, train y test. train se crea seleccionando la columna \"High\" del DataFRame dataset desde el índice tstart hasta el índice tend (ambos inclusive) y convirtiéndola en una matriz NumPy mediante el atributo values. test se crea seleccionando la columna \"High\" del DataFrame dataset desde el índice tend+1 hasta el final del DataFrame y convirtiéndola en una matriz NumPy mediante el atributo values. Por último, la función devuelve train y test. Fuera de la función, se llama a la función train_test_split con los argumentos dataset, tstart y tend. Las matrices train y test devueltas se asignan a las variables training_set y test_set, respectivamente."
      ],
      "metadata": {
        "id": "MbmJptDxqljC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialización del MinMaxScaler para normalizar datos al rango [0, 1]\n",
        "# - feature_range=(0,1) establece el rango de salida deseado\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Reformateo del array de entrenamiento a formato 2D requerido por scikit-learn\n",
        "# - reshape(-1, 1) convierte el array 1D [x1, x2,...] a 2D [[x1], [x2],...]\n",
        "# - -1 indica que numpy calcule automáticamente el tamaño de esa dimensión\n",
        "training_set = training_set.reshape(-1, 1)\n",
        "\n",
        "# Aplicación de la normalización (escalado)\n",
        "# - fit_transform() calcula parámetros (mín/máx) y transforma los datos en un solo paso\n",
        "# - Guarda los parámetros de escalado para poder invertirlo después\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "\n",
        "# Estructura resultante:\n",
        "# - training_set_scaled contendrá valores entre 0 y 1\n",
        "# - El objeto 'sc' almacena los parámetros para:\n",
        "#   - sc.inverse_transform() para revertir el escalado\n",
        "#   - sc.transform() para aplicar el mismo escalado a nuevos datos\n"
      ],
      "metadata": {
        "id": "iYP-1QxrqnjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sequence(sequence, n_steps):\n",
        "    \"\"\"\n",
        "    Divide una secuencia temporal en muestras para entrenamiento de modelos de aprendizaje secuencial.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    sequence : numpy.ndarray\n",
        "        Array 1D conteniendo la secuencia temporal escalada\n",
        "    n_steps : int\n",
        "        Número de pasos temporales a usar como ventana de entrada (timesteps)\n",
        "\n",
        "    Retorna:\n",
        "    --------\n",
        "    tuple: (X, y)\n",
        "        - X: Array 3D de muestras de entrada (muestras, timesteps, features)\n",
        "        - y: Array 1D de valores objetivo\n",
        "\n",
        "    \"\"\"\n",
        "    X, y = list(), list()\n",
        "    for i in range(len(sequence)):\n",
        "        # Calcula el índice final de la ventana actual\n",
        "        end_ix = i + n_steps\n",
        "        # Verifica si hemos alcanzado el final de la secuencia\n",
        "        if end_ix > len(sequence) - 1:\n",
        "            break\n",
        "        # Extrae la ventana de entrada (seq_x) y el valor objetivo (seq_y)\n",
        "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Configuración de parámetros\n",
        "n_steps = 60  # Número de días históricos para predecir el siguiente\n",
        "features = 1   # Usamos solo una característica (precio High)\n",
        "\n",
        "# Aplicación a los datos escalados\n",
        "X_train, y_train = split_sequence(training_set_scaled, n_steps)\n",
        "\n",
        "# Verificación de formas (shapes)\n",
        "print(f\"Forma de X_train: {X_train.shape}\")  # Debería ser (muestras, n_steps, features)\n",
        "print(f\"Forma de y_train: {y_train.shape}\")  # Debería ser (muestras,)\n",
        "\n",
        "# Reformateo para LSTM (muestras, timesteps, features)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], features))\n",
        "\n",
        "print(\"\\nForma final para LSTM:\")\n",
        "print(f\"X_train: {X_train.shape}\")  # (muestras, 60, 1)\n",
        "print(f\"y_train: {y_train.shape}\")  # (muestras,)"
      ],
      "metadata": {
        "id": "YmVxnAhirIe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorganización de los datos para el modelo LSTM/RNN\n",
        "\n",
        "\"\"\"\n",
        "Transformación de los datos de entrenamiento a formato 3D requerido por capas recurrentes:\n",
        "\n",
        "Formato requerido:\n",
        "(samples, timesteps, features)\n",
        "\n",
        "Donde:\n",
        "- samples: Número de muestras/ventanas temporales\n",
        "- timesteps: Pasos temporales por muestra (n_steps=60)\n",
        "- features: Variables predictoras (1 = solo precio High)\n",
        "\"\"\"\n",
        "\n",
        "X_train = X_train.reshape(\n",
        "    X_train.shape[0],  # Mantiene el mismo número de muestras (automático con -1)\n",
        "    X_train.shape[1],  # Mantiene los 60 timesteps\n",
        "    features           # 1 feature (podría ser >1 para múltiples variables)\n",
        ")\n",
        "\n",
        "# Verificación de la nueva forma\n",
        "print(\"Forma final de X_train:\", X_train.shape)\n",
        "print(f\"Muestras: {X_train.shape[0]}\")\n",
        "print(f\"Timesteps por muestra: {X_train.shape[1]}\")\n",
        "print(f\"Features por timestep: {X_train.shape[2]}\")\n",
        "\n",
        "# Ejemplo de visualización de una muestra\n",
        "print(\"\\nEjemplo de la primera muestra:\")\n",
        "print(X_train[0])  # Muestra los 60 timesteps con su feature"
      ],
      "metadata": {
        "id": "IHdiYxjAruEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo LSTM\n",
        "\n",
        "El modelo consta de una capa oculta única de LSTM y una capa de salida. Puedes experimentar con el número de unidades, ya que con más unidades obtendrás mejores resultados. Para este experimento, fijaremos las unidades LSTM en 125, tanh como activación y fijaremos el tamaño de entrada.\n",
        "\n"
      ],
      "metadata": {
        "id": "8Y1Y9blZr_V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The LSTM architecture\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(units=125, activation=\"tanh\", input_shape=(n_steps, features)))\n",
        "model_lstm.add(Dense(units=1))\n",
        "# Compiling the model\n",
        "model_lstm.compile(optimizer=\"RMSprop\", loss=\"mse\")\n",
        "\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "id": "c9Pte0MCr-XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.fit(X_train, y_train, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "id": "ijP5-C2UsRib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_total = dataset.loc[:,\"High\"]\n",
        "inputs = dataset_total[len(dataset_total) - len(test_set) - n_steps :].values\n",
        "inputs = inputs.reshape(-1, 1)\n",
        "#scaling\n",
        "inputs = sc.transform(inputs)\n",
        "\n",
        "# Split into samples\n",
        "X_test, y_test = split_sequence(inputs, n_steps)\n",
        "# reshape\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], features)\n",
        "#prediction\n",
        "predicted_stock_price = model_lstm.predict(X_test)\n",
        "#inverse transform the values\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
      ],
      "metadata": {
        "id": "M3iBi2SMsrcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(test, predicted):\n",
        "    \"\"\"\n",
        "    Visualiza comparación entre valores reales y predicciones del modelo.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    test : array-like\n",
        "        Valores reales de la serie temporal (normalmente el conjunto de prueba)\n",
        "    predicted : array-like\n",
        "        Valores predichos por el modelo (misma longitud que 'test')\n",
        "\n",
        "    Características del gráfico:\n",
        "    - Línea gris: Datos reales\n",
        "    - Línea roja: Predicciones\n",
        "    - Título y etiquetas descriptivas\n",
        "    - Leyenda para diferenciar series\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))  # Tamaño óptimo para series temporales\n",
        "    plt.plot(test, color=\"gray\", linewidth=2, label=\"Real\")\n",
        "    plt.plot(predicted, color=\"red\", linewidth=1.5, linestyle=\"--\", label=\"Predicted\")\n",
        "    plt.title(\"MasterCard Stock Price Prediction\", fontsize=14, pad=20)\n",
        "    plt.xlabel(\"Time\", fontsize=12)\n",
        "    plt.ylabel(\"MasterCard Stock Price (USD)\", fontsize=12)\n",
        "    plt.legend(fontsize=12, loc='upper left')\n",
        "    plt.grid(alpha=0.3)  # Grid suave para mejor lectura\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def return_rmse(test, predicted):\n",
        "    \"\"\"\n",
        "    Calcula e imprime el Error Cuadrático Medio (RMSE) entre valores reales y predicciones.\n",
        "\n",
        "    Parámetros:\n",
        "    -----------\n",
        "    test : array-like\n",
        "        Valores reales (ground truth)\n",
        "    predicted : array-like\n",
        "        Valores predichos por el modelo\n",
        "\n",
        "    RMSE (Root Mean Squared Error):\n",
        "    - Métrica estándar para evaluar modelos de series temporales\n",
        "    - Penaliza más los errores grandes (por el cuadrado)\n",
        "    - Misma unidad que la variable original (por la raíz cuadrada)\n",
        "    - Mientras más bajo, mejor el modelo\n",
        "\n",
        "    Salida:\n",
        "    - Imprime el valor con 2 decimales\n",
        "    - No retorna valor (solo imprime)\n",
        "    \"\"\"\n",
        "    rmse = np.sqrt(mean_squared_error(test, predicted))\n",
        "    print(\"\\nResultado de evaluación:\")\n",
        "    print(f\"The root mean squared error is {rmse:.2f}.\")\n",
        "    print(f\"En porcentaje del rango: {(rmse/(test.max()-test.min()))*100:.2f}%\")  # Contexto adicional"
      ],
      "metadata": {
        "id": "iIQlK3vSs58l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(test_set,predicted_stock_price)\n"
      ],
      "metadata": {
        "id": "-XW7sOZztNou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "return_rmse(test_set,predicted_stock_price)\n"
      ],
      "metadata": {
        "id": "y3W9sYMDtRhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo GRU**\n",
        "\n",
        "Vamos a mantener todo igual y solo vamos a sustituir la capa LSTM por la capa GRU para comparar adecuadamente los resultados. La estructura del modelo contiene una capa GRU única con 125 unidades y una capa de salida."
      ],
      "metadata": {
        "id": "LDuTcJNktaFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = Sequential()\n",
        "model_gru.add(GRU(units=125, activation=\"tanh\", input_shape=(n_steps, features)))\n",
        "model_gru.add(Dense(units=1))\n",
        "# Compiling the RNN\n",
        "model_gru.compile(optimizer=\"RMSprop\", loss=\"mse\")\n",
        "\n",
        "model_gru.summary()\n"
      ],
      "metadata": {
        "id": "9q4OZ9QGtXeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru.fit(X_train, y_train, epochs=50, batch_size=32)\n"
      ],
      "metadata": {
        "id": "UgxuHmg5tiPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_predicted_stock_price = model_gru.predict(X_test)\n",
        "GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)\n",
        "plot_predictions(test_set, GRU_predicted_stock_price)\n"
      ],
      "metadata": {
        "id": "4wZinER0tmym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "return_rmse(test_set,GRU_predicted_stock_price)\n"
      ],
      "metadata": {
        "id": "nW2JfuPOtyGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ver tutorial original:\n",
        "\n",
        "[https://www.datacamp.com/es/tutorial/tutorial-for-recurrent-neural-network](https://www.datacamp.com/es/tutorial/tutorial-for-recurrent-neural-network)\n"
      ],
      "metadata": {
        "id": "pUA-P-B6uCiS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADpq3XKgt39N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad\n",
        "\n",
        "**Predicción de Temperaturas usando RNN**\n",
        "\n",
        "Objetivo: Implementar modelos predictivos para series temporales de temperatura en España utilizando arquitecturas LSTM y GRU.\n",
        "\n",
        "Dataset: Temperaturas diarias en España\n",
        "\n",
        "**Fuente de datos:**\n",
        "\n",
        "[Dataset de Temperaturas de globales tomado de Kaggle](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dIqvYXWyZtve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"berkeleyearth/climate-change-earth-surface-temperature-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "print(os.listdir(path))\n",
        "\n",
        "\n",
        "# Construir la ruta completa al archivo deseado\n",
        "global_path = os.path.join(path, 'GlobalLandTemperaturesByCountry.csv')\n",
        "\n",
        "dataset_activity = pd.read_csv(\n",
        "    global_path)\n",
        "\n",
        "print(dataset_activity.head())\n",
        "\n",
        "display(dataset_activity)\n",
        "\n",
        "print(dataset_activity.columns)\n",
        "\n",
        "# Convertir la columna 'dt' a tipo datetime\n",
        "dataset_activity['dt'] = pd.to_datetime(dataset_activity['dt'])\n",
        "\n",
        "# Establecer 'dt' como índice\n",
        "dataset_activity.set_index('dt', inplace=True)\n",
        "\n",
        "# Filtrar para fechaAs después del año 1900 y para el país \"Spain\"\n",
        "dataset_activity = dataset_activity.loc[(dataset_activity.index.year > 1900) & (dataset_activity['Country'] == 'Spain'), ['AverageTemperature']]\n",
        "\n",
        "# Mostrar las primeras filas del resultado\n",
        "print(dataset_activity.head())"
      ],
      "metadata": {
        "id": "hqOmznheaTxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de los conjuntos de entrenamiento y prueba (modificar función antes de aplicar)\n"
      ],
      "metadata": {
        "id": "CnmdStHWfhXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracción de dos conjuntos: training_set, test_set (modificar función)\n"
      ],
      "metadata": {
        "id": "_062UcTJg97G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rango de salida deseado, formato (rshape) y escalar los datos\n",
        "\n"
      ],
      "metadata": {
        "id": "Fc-guXo8hOA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso de la función ya creada split_sequence (no hay que hacerle ningún cambio)\n",
        "\n",
        "#predecir 120 días\n"
      ],
      "metadata": {
        "id": "zInoizeXhR4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorganización de los datos para el modelo LSTM/RNN\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QrHxdZBRhWKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuración y compilación del modelo LSTM\n",
        "\n"
      ],
      "metadata": {
        "id": "O0HCmYF8hcZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste del modelo\n"
      ],
      "metadata": {
        "id": "3PBY4CEeheZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparación de datos para entrenamiento"
      ],
      "metadata": {
        "id": "V57tENoEhiTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gráfico y rmse modelo LSTM (funciones)\n",
        "\n"
      ],
      "metadata": {
        "id": "YYPke4q_hxdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gráfico y rmse modelo LSTM (aplicación de funciones con cambios)\n"
      ],
      "metadata": {
        "id": "puvQ4D6iutBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo GRU"
      ],
      "metadata": {
        "id": "F8EUh7ixwtNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configuración y compilación del modelo gru\n",
        "\n"
      ],
      "metadata": {
        "id": "Ycg0DMdNwr5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ajuste del modelo gru\n"
      ],
      "metadata": {
        "id": "SkXnK0XqwxWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráfico realses vs pronóstico\n"
      ],
      "metadata": {
        "id": "fdPB6Jw1w3We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculo del rmse gru\n"
      ],
      "metadata": {
        "id": "oo--DZhAxb14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}